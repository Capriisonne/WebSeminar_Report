\section{Topic models}

\subsection{Literature review}


\subsection{Latent dirichlet allocation}

Latent Dirichlet allocation (LDA) \cite{Blei:2003:LDA:944919.944937, heinrich2005parameter, steyvers} is a unsupervised machine learning technique 
that discovers latent topics from a corpus of documents so that the documents 
can then be assigned automatically into appropriate topics. New documents can 
also be classified into topics based on these latent topics. 
More specifically, in LDA, each document is represented as a mixture of various
topics, where each topic is a mixture of words. These mixtures are represented
by P(topic|document) for all topics and documents and P(word|topic) for all words 
in the vocabulary. Each word may occur in several different topics with a different probability, and each document is assumed to be characterized by a particular set of topics.


\subsection{Nonnegative Matrix Factorization}

Nonnegative matrix factorization (NMF) is an unsupervised family of algorithms that simultaneously perform dimension reduction and clustering.NMF was first introduced
by Paatero and Tapper \cite{paa94} as positive matrix factorization and subsequently
popularized by Lee and Seung \cite{lee99}.